{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae9bd59",
   "metadata": {},
   "source": [
    "# Assignment 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb221349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json\n",
    "import math \n",
    "import ast\n",
    "import re\n",
    "from itertools import islice\n",
    "from urllib.parse import quote  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0941c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load names/wiki links dictionary\n",
    "def extractDataFiles(filename):\n",
    "    marvel = pd.read_csv(filename +\".csv\")\n",
    "    marvel_wikilinks = marvel.loc[:, 'WikiLink']\n",
    "    marvel_characters = marvel_wikilinks[marvel_wikilinks.notna()].to_numpy()\n",
    "\n",
    "    all_marvel = {}\n",
    "\n",
    "    for name in marvel_characters:\n",
    "        character = name.replace(\" \", \"_\")\n",
    "        all_marvel[character] = character\n",
    "\n",
    "    return all_marvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b48c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. calling the functions\n",
    "marvel = extractDataFiles('marvel')\n",
    "dc = extractDataFiles('dc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b5824d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n",
      "1785\n"
     ]
    }
   ],
   "source": [
    "print(len(dc))\n",
    "print(len(marvel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "071e97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. create URL with given character_wiki_link\n",
    "# @returns NAME-> URL dict\n",
    "def createURLs(data_dir): \n",
    "    \n",
    "    url_query_list = {}\n",
    "    \n",
    "    for name,wiki in data_dir.items():        \n",
    "        baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "        action = \"action=query\"\n",
    "        title = \"titles=\" + wiki\n",
    "        content = \"prop=revisions&rvprop=content\"\n",
    "        only_links = \"prop=links&pllimit=max\"\n",
    "        dataformat =\"format=json\"\n",
    "        \n",
    "        query = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content, title,only_links, dataformat)\n",
    "        url_query_list[name] = query\n",
    "        \n",
    "    \n",
    "    return url_query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a884195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_url_query_directory_Links = createURLs(dc)\n",
    "marvel_url_query_directory_Links = createURLs(marvel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "38bfc33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n",
      "1785\n"
     ]
    }
   ],
   "source": [
    "print(len(DC_url_query_directory_Links))\n",
    "print(len(marvel_url_query_directory_Links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b086d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 create URL with given character_wiki_link\n",
    "# @returns NAME-> URL dict\n",
    "def createURLsPages(data_dir): \n",
    "    \n",
    "    url_query_list = {}\n",
    "    \n",
    "    for name,wiki in data_dir.items():        \n",
    "        baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "        action = \"action=query\"\n",
    "        title = \"titles=\" + wiki\n",
    "        content = \"prop=revisions&rvprop=content\"\n",
    "        only_links = \"&pllimit=max\"\n",
    "        dataformat =\"format=json\"\n",
    "        \n",
    "        query = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content, title,only_links, dataformat)\n",
    "        url_query_list[name] = query\n",
    "        \n",
    "    \n",
    "    return url_query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d16b0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_url_query_directory_pages = createURLsPages(marvel)\n",
    "DC_url_query_directory_pages = createURLsPages(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8fa47c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(DC_url_query_directory_pages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfe8f4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. Send request\n",
    "\n",
    "def sendWikiRequests(url_list):\n",
    "    response_wiki_dir = {}\n",
    "\n",
    "    for name,url in url_list.items():\n",
    "        try:\n",
    "            wikiresponse = urllib.request.urlopen(url)\n",
    "            wikidata = wikiresponse.read()\n",
    "            wikitext = wikidata.decode('utf-8')\n",
    "        \n",
    "            wiki_json = json.loads(wikitext)\n",
    "            response_wiki_dir[name] = wiki_json\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return response_wiki_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9e8138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_wiki_json_responses = sendWikiRequests(DC_url_query_directory_Links)\n",
    "marvel_wiki_json_responses = sendWikiRequests(marvel_url_query_directory_Links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74aa3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_wiki_responses_pages = sendWikiRequests(marvel_url_query_directory_pages)\n",
    "dc_wiki_responses_pages = sendWikiRequests(DC_url_query_directory_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f5a65f32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dcFUll = connectLinksPages(DC_wiki_json_responses, dc_wiki_responses_pages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9936b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvelFull = connectLinksPages(marvel_wiki_json_responses, marvel_wiki_responses_pages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "78a94e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectLinksPages(link_Directory,page_Directory):\n",
    "    full_dict = {}\n",
    "    \n",
    "    for name, wiki in link_Directory.items():\n",
    "        links = str(wiki)        \n",
    "        pages = str(page_Directory[name])\n",
    "        full = links + '***' + pages\n",
    "        full_dict[name] = full\n",
    "    return full_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cb45c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "import os.path\n",
    "\n",
    "def saveWikiJsonFiles(name_wiki,universe):\n",
    "    for name,wiki in name_wiki.items():\n",
    "        \n",
    "        save_path = str(universe)+'/'\n",
    "        name = name.replace('|','')\n",
    "        completeName = os.path.join(save_path, name+\".txt\")      \n",
    "        try:\n",
    "            with open(completeName, \"w\") as text_file:\n",
    "                    text_file.write(str(wiki))\n",
    "        except:\n",
    "            pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4a1c2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveWikiJsonFiles(marvelFull, 'marvel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0fc3b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveWikiJsonFiles(dcFUll, 'dc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c871b",
   "metadata": {},
   "source": [
    "# Part B: Building the networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f322f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readWikiJsonFiles(name_wiki,universe):\n",
    "    \n",
    "    name_wiki_json = {}\n",
    "    \n",
    "    for name,wiki in name_wiki.items():\n",
    "        temp = []\n",
    "        save_path = str(universe)+'/'\n",
    "        completeName = os.path.join(save_path, name+\".txt\") \n",
    "        try:\n",
    "            with open(completeName, \"r\") as text_file:\n",
    "                f = text_file.read()\n",
    "                name_wiki_json[name] = json.loads(json.dumps(f))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return name_wiki_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "015aafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_name_wiki = readWikiJsonFiles(dcFUll, 'dc')\n",
    "marvel_name_wiki = readWikiJsonFiles(marvelFull, 'marvel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d25a5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing full pages / links\n",
    "def splitLinksPages(text_file_list):\n",
    "    \n",
    "    name_wiki_dict = {}\n",
    "    \n",
    "    for name, wiki in text_file_list.items():\n",
    "        x = wiki.split(\"***\")    \n",
    "        name_wiki_dict[name] = x\n",
    "    \n",
    "    return name_wiki_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e8bc37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_name_wiki_processed = splitLinksPages(DC_name_wiki)\n",
    "marvel_name_wiki_processed = splitLinksPages(marvel_name_wiki)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "dc7d65c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before clean  452\n",
      "before clean2  1729\n"
     ]
    }
   ],
   "source": [
    "beforeClean = len(DC_name_wiki_processed)\n",
    "beforeClean2 = len(marvel_name_wiki_processed)\n",
    "\n",
    "print('before clean ' , beforeClean) # le nomber is OKE based on the CSV provided\n",
    "print('before clean2 ' , beforeClean2) # le nomber is OKE based on the CSV provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ebacfbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. extractLinks for each title,\n",
    "# @return array of names(links) to other pages\n",
    "def extractNodeNeighbors(directory):\n",
    "    \n",
    "    linkList = []\n",
    "    \n",
    "    for i in range(len(directory)):\n",
    "        ns = directory[i]['ns']\n",
    "        if(int(ns) != 0):\n",
    "            break\n",
    "        else:\n",
    "            title = directory[i]['title']\n",
    "            linkList.append(title)\n",
    "    \n",
    "    return linkList\n",
    "\n",
    "# 5.1 Check if site is redirect\n",
    "def checkIfRedirect(directory):\n",
    "    \n",
    "    for i in range(len(directory)):\n",
    "        ns = directory[i]['ns']\n",
    "        if(int(ns) == 4):\n",
    "            title = directory[i]['title']\n",
    "            if \"redirect\" in title: \n",
    "                print('redirect')\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "def wiki_json_preprocessing(directory):\n",
    "    \n",
    "    name_neighbors = {}\n",
    "    \n",
    "    for name,value_json in directory.items():\n",
    "        try:\n",
    "            value_json = value_json[0]\n",
    "            value_json = ast.literal_eval(value_json)\n",
    "        except:\n",
    "            continue\n",
    "        non_unique = value_json['query']['pages'].keys()\n",
    "        non_unique = next(iter(non_unique))\n",
    "        \n",
    "        try:    \n",
    "            link_dir = value_json['query']['pages'][non_unique]['links']\n",
    "        except:\n",
    "            continue\n",
    "        #check for redirect\n",
    "        \n",
    "        try:\n",
    "            if(checkIfRedirect(link_dir) == 0):\n",
    "                print(directory[name] + ' DELETED')\n",
    "                del directory[name]                \n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            node_neighbors = extractNodeNeighbors(link_dir)\n",
    "                \n",
    "        name_neighbors[name] = node_neighbors\n",
    "        \n",
    "    return name_neighbors      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c853b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_name_nodeLinks = wiki_json_preprocessing(marvel_name_wiki_processed)\n",
    "DC_name_nodeLinks = wiki_json_preprocessing(DC_name_wiki_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3a237584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after clean  378\n",
      "after clean2  1522\n",
      "difference  74\n",
      "difference2  207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('after clean ', len(DC_name_nodeLinks))\n",
    "print('after clean2 ', len(marvel_name_nodeLinks))\n",
    "\n",
    "\n",
    "print('difference ', beforeClean - len(DC_name_nodeLinks))\n",
    "print('difference2 ', beforeClean2 - len(marvel_name_nodeLinks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2f4df",
   "metadata": {},
   "source": [
    "**For each link you extract, check if the target is a character from your DC/Marvel lists. If yes, keep it. If no, discard it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "73aa48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkFromTargetUniverse(character_nodes, universe):\n",
    "    return list(set(character_nodes) & set(universe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7d16f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marvel check\n",
    "\n",
    "\n",
    "def removeRandomCharacters(name_links): \n",
    "    summ = 0\n",
    "    \n",
    "    for name, links in name_links.items():\n",
    "        x_dc = checkFromTargetUniverse(links, dc)\n",
    "        x_marvel = checkFromTargetUniverse(links, marvel)\n",
    "        \n",
    "        x_final = list(set().union(x_dc, x_marvel))\n",
    "        summ += len(x_final)\n",
    "        name_links[name] = x_final\n",
    "    \n",
    "    print('key -> value ::: sum of all edges in the values field ', summ)\n",
    "    \n",
    "    return name_links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "967c9518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marvel\n",
      "key -> value ::: sum of all edges in the values field  17373\n",
      "marvel nodes number :  1522\n",
      "\n",
      "dc\n",
      "key -> value ::: sum of all edges in the values field  5232\n",
      "DC nodes number  378\n"
     ]
    }
   ],
   "source": [
    "print('marvel')\n",
    "marvel_name_nodeLinks = removeRandomCharacters(marvel_name_nodeLinks)\n",
    "print('marvel nodes number : ', len((marvel_name_nodeLinks)))\n",
    "\n",
    "print()\n",
    "print('dc')\n",
    "DC_name_nodeLinks = removeRandomCharacters(DC_name_nodeLinks)\n",
    "print('DC nodes number ', len((DC_name_nodeLinks)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504391e9",
   "metadata": {},
   "source": [
    "#### Use a NetworkX DiGraph to store the network. As noted above, remember to store the properties of the nodes (i.e. from which universe they hail).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d0102f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "46575f64",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_edges_from() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [217]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, connections \u001b[38;5;129;01min\u001b[39;00m marvel_name_nodeLinks\u001b[38;5;241m.\u001b[39mitems(): \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(connections)):\n\u001b[1;32m---> 15\u001b[0m         \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_edges_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnections\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: add_edges_from() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# G.add_node('abc', dob=1185, pob='usa', dayob='monday')\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "#marvel\n",
    "for name, connections in marvel_name_nodeLinks.items():\n",
    "    G.add_node(name, universe = 'marvel')\n",
    "\n",
    "#dc\n",
    "for name, connections in DC_name_nodeLinks.items():\n",
    "    G.add_node(name, universe = 'dc')\n",
    "\n",
    "for name, connections in marvel_name_nodeLinks.items(): \n",
    "    for i in range(len(connections)):\n",
    "        G.add_edges_from(name, connections[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66257ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.number_of_edges())\n",
    "print('aaa')\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0625e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(G)\n",
    "\n",
    "# All degrees\n",
    "degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "degree_count = collections.Counter(degree_sequence)\n",
    "degrees, counts = zip(*degree_count.items())\n",
    "\n",
    "\n",
    "top_five = sorted(G.degree(), key=lambda x:x[1], reverse=True)[:50]\n",
    "print(\"Top five \", top_five)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "# In degrees\n",
    "degree_sequence = sorted([d for n, d in G.in_degree()], reverse=True)\n",
    "degree_count = collections.Counter(degree_sequence)\n",
    "in_degrees, in_counts = zip(*degree_count.items())\n",
    "\n",
    "# Out degrees\n",
    "degree_sequence = sorted([d for n, d in G.out_degree()], reverse=True)\n",
    "degree_count = collections.Counter(degree_sequence)\n",
    "out_degrees, out_counts = zip(*degree_count.items())\n",
    "\n",
    "plt.plot(degrees, counts, 'ro')\n",
    "plt.show()\n",
    "\n",
    "# The graph is pretty correct, the only problem is that V and War and the two most popular characters: Because other's match V and War easily,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1f71a",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs = [G.subgraph(c) for c in nx.weakly_connected_components(G)]\n",
    "\n",
    "# Probably not necessary to iterate\n",
    "GCC = subgraphs[0]\n",
    "print('aaa', type(GCC))\n",
    "print(GCC)\n",
    "for subgraph in subgraphs[1:]:\n",
    "    if subgraph.number_of_nodes() > GCC.number_of_nodes():\n",
    "        GCC = subgraph\n",
    "\n",
    "print(GCC)\n",
    "        \n",
    " # Universe attribute\n",
    "attributes_dict = {}\n",
    "for i in marvel_name_nodeLinks.keys():\n",
    "    attributes_dict[i] = \"marvel\"\n",
    "\n",
    "for i in DC_name_nodeLinks.keys():\n",
    "    attributes_dict[i] = \"dc\"\n",
    "\n",
    "nx.set_node_attributes(GCC, attributes_dict, name=\"universe\")\n",
    "\n",
    "GCC_undirected = GCC.to_undirected()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35eff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(GCC_undirected)\n",
    "\n",
    "node_colors = []\n",
    "\n",
    "for node in list(GCC_undirected.nodes()):\n",
    "    if GCC_undirected[node]['universe'] == 'dc':\n",
    "        node_color = \"#FF0000\"\n",
    "    else:\n",
    "        node_color = \"FFFF00\"\n",
    "    node_colors.append(node_color)    \n",
    "\n",
    "plt.figure(3,figsize=(12,16)) \n",
    "nx.draw(GCC_undirected, pos=pos, node_size=20, node_color = node_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cfe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_colors = []\n",
    "\n",
    "for node in list(GCC_undirected.nodes()):\n",
    "    if GCC_undirected[node]['universe'] == 'dc':\n",
    "        node_color = \"#FF0000\"\n",
    "    else:\n",
    "        node_color = \"FFFF00\"\n",
    "    node_colors.append(node_color)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fa2 import ForceAtlas2\n",
    "\n",
    "forceatlas2 = ForceAtlas2(\n",
    "                        # Behavior alternatives\n",
    "                        outboundAttractionDistribution=True,  # Dissuade hubs\n",
    "                        linLogMode=False,  # NOT IMPLEMENTED\n",
    "                        adjustSizes=False,  # Prevent overlap (NOT IMPLEMENTED)\n",
    "                        edgeWeightInfluence=1.0,\n",
    "\n",
    "                        # Performance\n",
    "                        jitterTolerance=1.0,  # Tolerance\n",
    "                        barnesHutOptimize=True,\n",
    "                        barnesHutTheta=1.2,\n",
    "                        multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                        # Tuning\n",
    "                        scalingRatio=2.0,\n",
    "                        strongGravityMode=False,\n",
    "                        gravity=1.0,\n",
    "\n",
    "                        # Log\n",
    "                        verbose=True)\n",
    "\n",
    "positions = forceatlas2.forceatlas2_networkx_layout(GCC_undirected, pos=None, iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = [d for n, d in GCC_undirected.degree()]\n",
    "degree_count = collections.Counter(degree_sequence)\n",
    "\n",
    "offset = 10\n",
    "scale = 200\n",
    "range = float(max(degree_sequence) - min(degree_sequence))\n",
    "node_sizes = [offset + scale * degree / range for degree in degree_sequence]\n",
    "\n",
    "nx.draw(GCC_undirected, pos=positions, node_size=node_sizes, width=0.15, node_color=node_colors, edgecolors=\"#000000\", linewidths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6f984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6c3ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9264cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceacc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d88899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04adff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd78e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8f6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2699ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10478499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fb862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f227c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
