{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae9bd59",
   "metadata": {},
   "source": [
    "# Assignment 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f559434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json\n",
    "import math \n",
    "import ast\n",
    "import re\n",
    "from itertools import islice\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da35a04",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0941c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load names/wiki links dictionary\n",
    "def extractDataFiles(filename):\n",
    "    marvel = pd.read_csv(filename +\".csv\")\n",
    "    marvel_wikilinks = marvel.loc[:, 'WikiLink']\n",
    "    marvel_characters = marvel_wikilinks[marvel_wikilinks.notna()].to_numpy()\n",
    "\n",
    "    all_marvel = {}\n",
    "\n",
    "    for name in marvel_characters:\n",
    "        character = name.replace(\" \", \"_\")\n",
    "        all_marvel[character] = character\n",
    "\n",
    "    return all_marvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b48c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. calling the functions\n",
    "marvel = extractDataFiles('marvel')\n",
    "dc = extractDataFiles('dc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5824d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n",
      "1785\n"
     ]
    }
   ],
   "source": [
    "print(len(dc))\n",
    "print(len(marvel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071e97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. create URL with given character_wiki_link\n",
    "# @returns NAME-> URL dict\n",
    "def createURLs(data_dir): \n",
    "    \n",
    "    url_query_list = {}\n",
    "    \n",
    "    for name,wiki in data_dir.items():        \n",
    "        baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "        action = \"action=query\"\n",
    "        title = \"titles=\" + wiki\n",
    "        content = \"prop=revisions&rvprop=content\"\n",
    "        only_links = \"prop=links&pllimit=max\"\n",
    "        dataformat =\"format=json\"\n",
    "        \n",
    "        query = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content, title,only_links, dataformat)\n",
    "        url_query_list[name] = query\n",
    "        \n",
    "    \n",
    "    return url_query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a884195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_url_query_directory_Links = createURLs(dc)\n",
    "marvel_url_query_directory_Links = createURLs(marvel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38bfc33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n",
      "1785\n"
     ]
    }
   ],
   "source": [
    "print(len(DC_url_query_directory_Links))\n",
    "print(len(marvel_url_query_directory_Links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b086d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 create URL with given character_wiki_link\n",
    "# @returns NAME-> URL dict\n",
    "def createURLsPages(data_dir): \n",
    "    \n",
    "    url_query_list = {}\n",
    "    \n",
    "    for name,wiki in data_dir.items():        \n",
    "        baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "        action = \"action=query\"\n",
    "        title = \"titles=\" + wiki\n",
    "        content = \"prop=revisions&rvprop=content\"\n",
    "        only_links = \"&pllimit=max\"\n",
    "        dataformat =\"format=json\"\n",
    "        \n",
    "        query = \"{}{}&{}&{}&{}&{}\".format(baseurl, action, content, title,only_links, dataformat)\n",
    "        url_query_list[name] = query\n",
    "        \n",
    "    \n",
    "    return url_query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d16b0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_url_query_directory_pages = createURLsPages(marvel)\n",
    "DC_url_query_directory_pages = createURLsPages(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fa47c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(DC_url_query_directory_pages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe8f4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. Send request\n",
    "\n",
    "def sendWikiRequests(url_list):\n",
    "    response_wiki_dir = {}\n",
    "\n",
    "    for name,url in url_list.items():\n",
    "        try:\n",
    "            wikiresponse = urllib.request.urlopen(url)\n",
    "            wikidata = wikiresponse.read()\n",
    "            wikitext = wikidata.decode('utf-8')\n",
    "        \n",
    "            wiki_json = json.loads(wikitext)\n",
    "            response_wiki_dir[name] = wiki_json\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return response_wiki_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9e8138a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DC_wiki_json_responses = sendWikiRequests(DC_url_query_directory_Links)\n",
    "marvel_wiki_json_responses = sendWikiRequests(marvel_url_query_directory_Links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74aa3199",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "marvel_wiki_responses_pages = sendWikiRequests(marvel_url_query_directory_pages)\n",
    "dc_wiki_responses_pages = sendWikiRequests(DC_url_query_directory_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f909d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectLinksPages(link_Directory,page_Directory):\n",
    "    full_dict = {}\n",
    "    \n",
    "    for name, wiki in link_Directory.items():\n",
    "        links = str(wiki)        \n",
    "        pages = str(page_Directory[name])\n",
    "        full = links + '***' + pages\n",
    "        full_dict[name] = full\n",
    "    return full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a65f32",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dcFUll = connectLinksPages(DC_wiki_json_responses, dc_wiki_responses_pages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9936b020",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "marvelFull = connectLinksPages(marvel_wiki_json_responses, marvel_wiki_responses_pages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb45c0a",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save to file\n",
    "import os.path\n",
    "\n",
    "def saveWikiJsonFiles(name_wiki,universe):\n",
    "    for name,wiki in name_wiki.items():\n",
    "        \n",
    "        save_path = str(universe)+'/'\n",
    "        name = name.replace('|','')\n",
    "        completeName = os.path.join(save_path, name+\".txt\")      \n",
    "        try:\n",
    "            with open(completeName, \"w\") as text_file:\n",
    "                    text_file.write(str(wiki))\n",
    "        except:\n",
    "            pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c2298",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "saveWikiJsonFiles(marvelFull, 'marvel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3b88b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "saveWikiJsonFiles(dcFUll, 'dc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322f474",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def readWikiJsonFiles(name_wiki,universe):\n",
    "    \n",
    "    name_wiki_json = {}\n",
    "    \n",
    "    for name,wiki in name_wiki.items():\n",
    "        temp = []\n",
    "        save_path = str(universe)+'/'\n",
    "        completeName = os.path.join(save_path, name+\".txt\") \n",
    "        try:\n",
    "            with open(completeName, \"r\") as text_file:\n",
    "                f = text_file.read()\n",
    "                name_wiki_json[name] = json.loads(json.dumps(f))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return name_wiki_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015aafe4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DC_name_wiki = readWikiJsonFiles(dcFUll, 'dc')\n",
    "marvel_name_wiki = readWikiJsonFiles(marvelFull, 'marvel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a5d61",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing full pages / links\n",
    "def splitLinksPages(text_file_list):\n",
    "    \n",
    "    name_wiki_dict = {}\n",
    "    \n",
    "    for name, wiki in text_file_list.items():\n",
    "        x = wiki.split(\"***\")    \n",
    "        name_wiki_dict[name] = x\n",
    "    \n",
    "    return name_wiki_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc37f9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DC_name_wiki_processed = splitLinksPages(DC_name_wiki)\n",
    "marvel_name_wiki_processed = splitLinksPages(marvel_name_wiki)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d65c3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "beforeClean = len(DC_name_wiki_processed)\n",
    "beforeClean2 = len(marvel_name_wiki_processed)\n",
    "\n",
    "print('before clean ' , beforeClean) # le nomber is OKE based on the CSV provided\n",
    "print('before clean2 ' , beforeClean2) # le nomber is OKE based on the CSV provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebacfbe0",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. extractLinks for each title,\n",
    "# @return array of names(links) to other pages\n",
    "def extractNodeNeighbors(directory):\n",
    "    \n",
    "    linkList = []\n",
    "    \n",
    "    for i in range(len(directory)):\n",
    "        ns = directory[i]['ns']\n",
    "        if(int(ns) != 0):\n",
    "            break\n",
    "        else:\n",
    "            title = directory[i]['title']\n",
    "            linkList.append(title)\n",
    "    \n",
    "    return linkList\n",
    "\n",
    "# 5.1 Check if site is redirect\n",
    "def checkIfRedirect(directory):\n",
    "    \n",
    "    for i in range(len(directory)):\n",
    "        ns = directory[i]['ns']\n",
    "        if(int(ns) == 4):\n",
    "            title = directory[i]['title']\n",
    "            if \"redirect\" in title: \n",
    "                print('redirect')\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "def wiki_json_preprocessing(directory):\n",
    "    \n",
    "    name_neighbors = {}\n",
    "    \n",
    "    for name,value_json in directory.items():\n",
    "        try:\n",
    "            value_json = value_json[0]\n",
    "            value_json = ast.literal_eval(value_json)\n",
    "        except:\n",
    "            continue\n",
    "        non_unique = value_json['query']['pages'].keys()\n",
    "        non_unique = next(iter(non_unique))\n",
    "        \n",
    "        try:    \n",
    "            link_dir = value_json['query']['pages'][non_unique]['links']\n",
    "        except:\n",
    "            continue\n",
    "        #check for redirect\n",
    "        \n",
    "        try:\n",
    "            if(checkIfRedirect(link_dir) == 0):\n",
    "                print(directory[name] + ' DELETED')\n",
    "                del directory[name]                \n",
    "                continue\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            node_neighbors = extractNodeNeighbors(link_dir)\n",
    "                \n",
    "        name_neighbors[name] = node_neighbors\n",
    "        \n",
    "    return name_neighbors      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853b752",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "marvel_name_nodeLinks = wiki_json_preprocessing(marvel_name_wiki_processed)\n",
    "DC_name_nodeLinks = wiki_json_preprocessing(DC_name_wiki_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a237584",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print('after clean ', len(DC_name_nodeLinks))\n",
    "print('after clean2 ', len(marvel_name_nodeLinks))\n",
    "\n",
    "\n",
    "print('difference ', beforeClean - len(DC_name_nodeLinks))\n",
    "print('difference2 ', beforeClean2 - len(marvel_name_nodeLinks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2f4df",
   "metadata": {},
   "source": [
    "**For each link you extract, check if the target is a character from your DC/Marvel lists. If yes, keep it. If no, discard it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa48e4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def checkFromTargetUniverse(character_nodes, universe):\n",
    "    return list(set(character_nodes) & set(universe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16f8a7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Marvel check\n",
    "\n",
    "\n",
    "def removeRandomCharacters(name_links): \n",
    "    summ = 0\n",
    "    \n",
    "    for name, links in name_links.items():\n",
    "        x_dc = checkFromTargetUniverse(links, dc)\n",
    "        x_marvel = checkFromTargetUniverse(links, marvel)\n",
    "        \n",
    "        x_final = list(set().union(x_dc, x_marvel))\n",
    "        summ += len(x_final)\n",
    "        name_links[name] = x_final\n",
    "    \n",
    "    print('key -> value ::: sum of all edges in the values field ', summ)\n",
    "    \n",
    "    return name_links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c9518",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('marvel')\n",
    "marvel_name_nodeLinks = removeRandomCharacters(marvel_name_nodeLinks)\n",
    "print('marvel nodes number : ', len((marvel_name_nodeLinks)))\n",
    "\n",
    "print()\n",
    "print('dc')\n",
    "DC_name_nodeLinks = removeRandomCharacters(DC_name_nodeLinks)\n",
    "print('DC nodes number ', len((DC_name_nodeLinks)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504391e9",
   "metadata": {},
   "source": [
    "#### Use a NetworkX DiGraph to store the network. As noted above, remember to store the properties of the nodes (i.e. from which universe they hail).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0102f56",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46575f64",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# G.add_node('abc', dob=1185, pob='usa', dayob='monday')\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "#marvel\n",
    "for name, connections in marvel_name_nodeLinks.items():\n",
    "    G.add_node(name, universe = 'marvel')\n",
    "\n",
    "#dc\n",
    "for name, connections in DC_name_nodeLinks.items():\n",
    "    G.add_node(name, universe = 'dc')\n",
    "\n",
    "for name, connections in marvel_name_nodeLinks.items(): \n",
    "    for i in range(len(connections)):\n",
    "        G.add_edges_from(name, connections[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1f71a",
   "metadata": {},
   "source": [
    "### Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf99a9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Get basic stats, mean, median etc... (once this runs and a proper graph is constructed :)\n",
    "print(G.number_of_edges())\n",
    "print(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0625e7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Get stats for in- and out- degree distribution\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(G)\n",
    "\n",
    "# All degrees\n",
    "degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "degree_count = collections.Counter(degree_sequence)\n",
    "degrees, counts = zip(*degree_count.items())\n",
    "\n",
    "\n",
    "top_five = sorted(G.degree(), key=lambda x:x[1], reverse=True)[:50]\n",
    "print(\"Top five \", top_five)\n",
    "print()\n",
    "\n",
    "# In degrees\n",
    "degree_sequence = sorted([d for n, d in G.in_degree()], reverse=True)\n",
    "degree_count = collections.Counter(degree_sequence)\n",
    "in_degrees, in_counts = zip(*degree_count.items())\n",
    "\n",
    "# Out degrees\n",
    "degree_sequence = sorted([d for n, d in G.out_degree()], reverse=True)\n",
    "degree_count = collections.Counter(degree_sequence)\n",
    "out_degrees, out_counts = zip(*degree_count.items())\n",
    "\n",
    "plt.plot(degrees, counts, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10722a",
   "metadata": {},
   "source": [
    "The number of nodes is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c35f8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "subgraphs = [G.subgraph(c) for c in nx.weakly_connected_components(G)]\n",
    "\n",
    "# Probably not necessary to iterate\n",
    "GCC = subgraphs[0]\n",
    "print('aaa', type(GCC))\n",
    "print(GCC)\n",
    "for subgraph in subgraphs[1:]:\n",
    "    if subgraph.number_of_nodes() > GCC.number_of_nodes():\n",
    "        GCC = subgraph\n",
    "\n",
    "print(GCC)\n",
    "        \n",
    " # Universe attribute\n",
    "attributes_dict = {}\n",
    "for i in marvel_name_nodeLinks.keys():\n",
    "    attributes_dict[i] = \"marvel\"\n",
    "\n",
    "for i in DC_name_nodeLinks.keys():\n",
    "    attributes_dict[i] = \"dc\"\n",
    "\n",
    "nx.set_node_attributes(GCC, attributes_dict, name=\"universe\")\n",
    "\n",
    "GCC_undirected = GCC.to_undirected()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35eff35",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(GCC_undirected)\n",
    "\n",
    "node_colors = []\n",
    "\n",
    "for node in list(GCC_undirected.nodes()):\n",
    "    if GCC_undirected[node]['universe'] == 'dc':\n",
    "        node_color = \"#FF0000\"\n",
    "    else:\n",
    "        node_color = \"FFFF00\"\n",
    "    node_colors.append(node_color)    \n",
    "\n",
    "plt.figure(3,figsize=(12,16)) \n",
    "nx.draw(GCC_undirected, pos=pos, node_size=20, node_color = node_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40db87",
   "metadata": {},
   "source": [
    "Plotting the network..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cfe72",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "node_colors = []\n",
    "\n",
    "for node in list(GCC_undirected.nodes()):\n",
    "    if GCC_undirected[node]['universe'] == 'dc':\n",
    "        node_color = \"#FF0000\"\n",
    "    else:\n",
    "        node_color = \"FFFF00\"\n",
    "    node_colors.append(node_color)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fcf5b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from fa2 import ForceAtlas2\n",
    "\n",
    "forceatlas2 = ForceAtlas2(\n",
    "                        # Behavior alternatives\n",
    "                        outboundAttractionDistribution=True,  # Dissuade hubs\n",
    "                        linLogMode=False,  # NOT IMPLEMENTED\n",
    "                        adjustSizes=False,  # Prevent overlap (NOT IMPLEMENTED)\n",
    "                        edgeWeightInfluence=1.0,\n",
    "\n",
    "                        # Performance\n",
    "                        jitterTolerance=1.0,  # Tolerance\n",
    "                        barnesHutOptimize=True,\n",
    "                        barnesHutTheta=1.2,\n",
    "                        multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                        # Tuning\n",
    "                        scalingRatio=2.0,\n",
    "                        strongGravityMode=False,\n",
    "                        gravity=1.0,\n",
    "\n",
    "                        # Log\n",
    "                        verbose=True)\n",
    "\n",
    "positions = forceatlas2.forceatlas2_networkx_layout(GCC_undirected, pos=None, iterations=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d521b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "degree_sequence = [d for n, d in GCC_undirected.degree()]\n",
    "degree_count = collections.Counter(degree_sequence)\n",
    "\n",
    "offset = 10\n",
    "scale = 200\n",
    "range = float(max(degree_sequence) - min(degree_sequence))\n",
    "node_sizes = [offset + scale * degree / range for degree in degree_sequence]\n",
    "\n",
    "nx.draw(GCC_undirected, pos=positions, node_size=node_sizes, width=0.15, node_color=node_colors, edgecolors=\"#000000\", linewidths=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b209f",
   "metadata": {},
   "source": [
    "### Communities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a188d3",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5102d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
